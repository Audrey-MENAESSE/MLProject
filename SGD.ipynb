{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New test with SGD without large output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "import os\n",
    "DATA_TRAIN_PATH = r'C:\\Users\\Audrey\\Documents\\Cours\\MLrandom\\data\\train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids, headers = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this value 7343\n",
    "tX = np.delete(tX, 7343, axis = 0)\n",
    "y = np.delete(y, 7343, axis = 0)\n",
    "ids = np.delete(ids, 7343)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values replacement and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_ (feature) :\n",
    "    values=[]\n",
    "    for i in range (len(feature)):\n",
    "        if feature[i]!=-999:\n",
    "            values.append(feature[i])\n",
    "    mean = np.mean(values)\n",
    "    sd = np.std(values)\n",
    "    return (mean, sd)\n",
    "\n",
    "def normalize (tX) :\n",
    "    tX_norm = tX\n",
    "    for i in range (len(tX[0])):\n",
    "        if i!=22 :\n",
    "            mean, sd = norm_(tX[i])\n",
    "            for j in range(len(tX)) :\n",
    "                if tX[j,i]==-999 :\n",
    "                    tX_norm[j,i]=0\n",
    "                else :\n",
    "                    tX_norm[j,i]=(tX[j,i]-mean)/sd\n",
    "    return tX_norm\n",
    "\n",
    "def cat_features (tX, num_column) :\n",
    "    # For this dataset, the only categorical feature is column 22\n",
    "    # The possible entries of feature PRI_jet_num are 0, 1, 2, 3\n",
    "    inds0 = np.where(tX[:, num_column] == 0)\n",
    "    inds1 = np.where(tX[:, num_column] == 1)\n",
    "    inds2 = np.where(tX[:, num_column] == 2)\n",
    "    inds3 = np.where(tX[:, num_column] == 3)\n",
    "\n",
    "    # initialize new columns as zeros\n",
    "    pri_jet0 = np.zeros(tX.shape[0])\n",
    "    pri_jet1 = np.zeros(tX.shape[0])\n",
    "    pri_jet2 = np.zeros(tX.shape[0])\n",
    "    pri_jet3 = np.zeros(tX.shape[0])\n",
    "\n",
    "    # set ones to appropriate columns\n",
    "    pri_jet0[inds0] = 1\n",
    "    pri_jet1[inds1] = 1\n",
    "    pri_jet2[inds2] = 1\n",
    "    pri_jet3[inds3] = 1\n",
    "\n",
    "    # concatenate new features to tX\n",
    "    tX= np.delete(tX, num_column, axis = 1)\n",
    "    tX = np.column_stack((tX, pri_jet0, pri_jet1, pri_jet2, pri_jet3))\n",
    "    return tX\n",
    "\n",
    "def PCA_bias (tX) :\n",
    "    m, n = tX.shape\n",
    "    dataset=tX\n",
    "    dataset -= tX.mean(axis=0)\n",
    "    R = np.cov(dataset, rowvar=False)\n",
    "    evals, evects = np.linalg.eigh(R)\n",
    "    # Sorting the eigenvalues in a decreasing order\n",
    "    index = np.argsort(evals)[::-1]\n",
    "    evals = evals[index]\n",
    "    evects = evects[:,index]\n",
    "    #evects = evects[:, :n_features]\n",
    "    data = np.dot(evects.T, dataset.T).T\n",
    "    \n",
    "    # Adding the bias term of the model\n",
    "    data_ones = np.c_[np.ones((len(tX), 1)), data]\n",
    "    \n",
    "    return (data_ones)\n",
    "\n",
    "def arrange_data (tX) :\n",
    "    tX_prep = cat_features(normalize(tX), 22)\n",
    "    data = PCA_bias(tX_prep)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arrange_data (tX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249999, 34)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of a training and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199999, 34)\n"
     ]
    }
   ],
   "source": [
    "def split_train_test (y, tX, ratio_train) : \n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    num_row = y.shape[0]\n",
    "    indices = np.random.permutation(num_row)\n",
    "    limit = int(num_row*ratio_train)\n",
    "    for i in range(num_row):\n",
    "        if i<limit :\n",
    "            x_train.append(tX[indices[i]])\n",
    "            y_train.append(y[indices[i]])\n",
    "        else :\n",
    "            x_test.append(tX[indices[i]])\n",
    "            y_test.append(y[indices[i]])\n",
    "    return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_train_test(y, data, 0.8)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    e= y - tx.dot(w)\n",
    "    X = np.transpose(tx)\n",
    "    gradient = -(X.dot(e))/len(y)\n",
    "    return (gradient)\n",
    "\n",
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    w = initial_w\n",
    "    loss = compute_loss(y,tx,w)\n",
    "    losses = [loss]\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        DL = compute_gradient(y,tx,w)\n",
    "        loss = compute_loss(y,tx,w)\n",
    "        w = w - gamma*DL\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "    return losses[-1], ws[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones(len(x_train[0]))\n",
    "loss, coeffs = gradient_descent(y_train, x_train, initial_w, 100000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31408513  0.01877354 -0.01924595  0.00205096  0.08755195 -0.01404975\n",
      "  0.04271845 -0.13216246 -0.2428544   0.08774975  0.12945402 -0.14163845\n",
      " -0.09373998 -0.03486062  0.04812387 -0.26259455 -0.35576724 -0.27358864\n",
      " -0.06133017 -0.04695701 -0.02005821  0.08437736  0.19218647  0.31175787\n",
      " -0.20910215  0.08748881  0.67926548 -0.46822699  0.89283116 -0.04302604\n",
      "  0.25054063  1.15383636  1.00001109  1.        ]\n"
     ]
    }
   ],
   "source": [
    "print (coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73.572 % of correct predictions\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy (y_test, x_test, coeffs) :\n",
    "    y_pred = x_test.dot(coeffs)\n",
    "    N = len (y_test)\n",
    "    T = 0\n",
    "    F = 0\n",
    "    for i in range (N) :\n",
    "        if y_test[i]*y_pred[i]>0:\n",
    "            T+=1\n",
    "        else : \n",
    "            F+=1\n",
    "    accuracy = 100*T/N\n",
    "    print(\"There are {acc} % of correct predictions\".format(\n",
    "              acc = accuracy))\n",
    "    \n",
    "calculate_accuracy(y_test, x_test, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = r'C:\\Users\\Audrey\\Documents\\Cours\\MLrandom\\data\\test.csv' # TODO: download train data and supply path here \n",
    "f, tX_test, ids_test, headers_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = r'C:\\Users\\Audrey\\Documents\\Cours\\MLrandom\\data\\submit.csv' # TODO: fill in desired name of output file for submission\n",
    "data_test = arrange_data(tX_test)\n",
    "y_pred = predict_labels(coeffs, data_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
